{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIFDFARV6JMCL4epVnQgt4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KJ22222/ESSA/blob/main/9_26_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7장 앙상블 학습과 랜덤 포레스트"
      ],
      "metadata": {
        "id": "hiNMv2lVqoRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결정 트리의 앙상블->랜덤 포레스트\n",
        "- 앙상블 방법:배깅,부스팅 스태킹"
      ],
      "metadata": {
        "id": "0sIsA4gWqtpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.1 투표 기반 분류기\n",
        "- 각 분류기가 약한 학습기라도 충분하게 많고 다양하다면 앙상블은 강한 학습기가 될 수 있음\n",
        "- 각 분류기가 완벽하게 독립적이고 오차에 상관관계가 없어야 가능하지만 같은 데이터로 훈련시키기 때문에 불가능\n",
        "- 분류기는 같은 종류의 오차를 만들기 쉽기 때문에 잘못된 클래스가 다수인 경우가 많고 앙상블 정확도가 낮아짐"
      ],
      "metadata": {
        "id": "56Li9rc3q7-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###여러분류기를 조합하여 만든 투표 기반 분류기"
      ],
      "metadata": {
        "id": "u06pCjjHr8dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "간접 투표(voting='hard')"
      ],
      "metadata": {
        "id": "EV9yVGpysxEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "stnSBPIWr6DD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard')\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A71zv66zscDy",
        "outputId": "3d411b74-9339-4417-f8bc-6da5be16ac1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 분류기의 데스트셋 정확도 확인"
      ],
      "metadata": {
        "id": "je4avuN_sjD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzXRPg1xqhAf",
        "outputId": "e8bc8162-f867-448a-c621-6009edb45d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.912\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "간접 투표"
      ],
      "metadata": {
        "id": "5pBcduddstEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "og_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='soft')\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxTimp_Ks-Qb",
        "outputId": "605283de-1757-4452-df78-e762c67b0088"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk_czu1QtBFr",
        "outputId": "e9d0f584-b94e-4f0a-aad4-aeee257b38dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.2 배깅과 페이스팅\n",
        "- 배깅:같은 알고리즘을 사용하고 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 것,훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "- 페이스팅: 중복을 허용하지 않고 샘플링\n",
        "- 편향과 분산이 모두 감소\n",
        "- 배깅이 페이스팅보다 편향이 조금 더 높음.하지만 다양성을 증가시키므로 분산이 감소\n"
      ],
      "metadata": {
        "id": "jTFgaCKZtDxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2.1 사이킷런의 배깅과 페이스팅"
      ],
      "metadata": {
        "id": "nIFgUAbdt3Y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaggingClassifier"
      ],
      "metadata": {
        "id": "CENim8H5u3ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "0YPPBdhnt7NR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPh1Xbl0ulRh",
        "outputId": "69086350-b8fa-4201-be04-93d192b90798"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "7hD_NKthu0Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27fPFeUumpx",
        "outputId": "7b2f81ca-688b-43bc-deee-79e30c997e93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2.2 oob 평가"
      ],
      "metadata": {
        "id": "QYRJ-nJAu4ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
        "    bootstrap=True, oob_score=True, random_state=40)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mahuZ8WAuzP-",
        "outputId": "03e4c47c-cdcb-448b-f8d9-ad8aaca7489f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8986666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkM0pg1jvFhk",
        "outputId": "cfd7bfe7-bb1c-42b7-d40d-40f21f575e2e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.912"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 훈련 샘플의 클래스 확률을 반환함"
      ],
      "metadata": {
        "id": "T6jzoCZ8vYC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6wqnLQ0vR-N",
        "outputId": "62a112bd-17df-4452-e0a6-9bfe17698753"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32275132, 0.67724868],\n",
              "       [0.34117647, 0.65882353],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.09497207, 0.90502793],\n",
              "       [0.31147541, 0.68852459],\n",
              "       [0.01754386, 0.98245614],\n",
              "       [0.97109827, 0.02890173],\n",
              "       [0.97765363, 0.02234637]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.4 랜덤 포레스트"
      ],
      "metadata": {
        "id": "cSSPaq0nvc8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정트리"
      ],
      "metadata": {
        "id": "9s1_gqOMv5Iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=42),\n",
        "    n_estimators=500, max_samples=1.0, bootstrap=True, random_state=42)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "GLWYiSqyv1Oo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트"
      ],
      "metadata": {
        "id": "4WC1uXZev6Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "fncmKFzHv8Gm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "트리의 노드를 분할할 때 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입시켜 트리를 다양하게 만들고 편향을 손해보는 대신 분산을 낮추어 더 훌륭한 모델"
      ],
      "metadata": {
        "id": "pkK-UfdnwD4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.sum(y_pred == y_pred_rf) / len(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giQW-UzuwUdj",
        "outputId": "1b349ce9-c76a-41dc-e18c-ff74db90338c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.976"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.4.1 익스트림 랜덤 트리\n",
        "- 극단적으로 무작위한 트리의 랜덤 포레스트\n",
        "- 보통보다 더 빠름"
      ],
      "metadata": {
        "id": "AK3S2HnbwcoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.4.2 특성 중요도\n",
        "- 랜덤포레스트의 장점:사이킷런은 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도를 측정\n",
        "- 합이 1이 되도록 하여 피처의 중요도를 나타냄"
      ],
      "metadata": {
        "id": "kI5-J1epw5J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBhV6mlpxMRE",
        "outputId": "3614c9c3-afe1-4f8f-ecca-382397bcff76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.11249225099876375\n",
            "sepal width (cm) 0.02311928828251033\n",
            "petal length (cm) 0.4410304643639577\n",
            "petal width (cm) 0.4233579963547682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.5 부스팅\n",
        "- 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법"
      ],
      "metadata": {
        "id": "5L2sDkRNxXan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.5.1 에이다부스트\n",
        "- 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것->학습하기 어려웠던 샘플에 점점 예측기가 맞춰짐"
      ],
      "metadata": {
        "id": "n4tv_WUaxTFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "uwsIcA1_xSmH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.5.2 그레이디언트 부스팅\n",
        "- 앙상블 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가\n",
        "- 이전 예측기가 만든 잔여 오차에 새로운 예측기를 학습시킴"
      ],
      "metadata": {
        "id": "Qz9SgQEillfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgvX-3QCl1lF",
        "outputId": "922bac06-b642-4ce8-a033-c7f75249bb2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNlseHfomBmL",
        "outputId": "266afb59-737d-48e6-e41b-1f817a4b461f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_FtOc2XmDpZ",
        "outputId": "db2d8052-8079-4ff6-816d-dcada97a621e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로운 샘플에 대한 예측을 만드려면 모든 트리의 예측을 더함"
      ],
      "metadata": {
        "id": "rjislyDOmH4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array([[0.8]])"
      ],
      "metadata": {
        "id": "GhbuzMaZmPya"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500)\n",
        "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
        "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
        "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
        "    if label or data_label:\n",
        "        plt.legend(loc=\"upper center\", fontsize=16)\n",
        "    plt.axis(axes)"
      ],
      "metadata": {
        "id": "HKkanmI-mmLH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
        "gbrt.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpCgFf-ampwS",
        "outputId": "3c70612a-57ee-45c8-aaa9-1fce2613d4ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3,\n",
              "                          random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt_slow = GradientBoostingRegressor(max_depth=2, n_estimators=200, learning_rate=0.1, random_state=42)\n",
        "gbrt_slow.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0zEsDh3nURD",
        "outputId": "5070233c-910d-48a6-d3c9-22c221304a24"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0GhL7wqnbb3",
        "outputId": "f2bbb82f-81c6-4f50-801c-6d0d894a7abe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=105, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.6 스태킹"
      ],
      "metadata": {
        "id": "gzEMurUfnfe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는 모델을 훈련시키기"
      ],
      "metadata": {
        "id": "27DMCKL0nxOg"
      }
    }
  ]
}